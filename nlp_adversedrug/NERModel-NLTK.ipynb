{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import untangle\n",
    "import glob\n",
    "from mitie import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NERModel:\n",
    "\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        initiate class object\n",
    "        '''\n",
    "        self.trainer = ner_trainer(\"/Users/jzhu/MITIE/MITIE-models/english/total_word_feature_extractor.dat\")\n",
    "        self.ner = None\n",
    "\n",
    "    def parse_train_xml(self, filename):\n",
    "        \"\"\"\n",
    "        @input a filename string\n",
    "        @return:\n",
    "        For training data: both a dictionary (key is the section) for X (text strings)\n",
    "        and a list of dictionary for y (keys: id (not for task 1), section, type, start, len)\n",
    "        \"\"\"\n",
    "        X = {}\n",
    "        Y = []\n",
    "\n",
    "        obj = untangle.parse(filename)\n",
    "        for text in obj.Label.Text.Section:\n",
    "            X[text['id']] = text.cdata\n",
    "\n",
    "        if obj.Label.Mentions.Mention:\n",
    "            for mention in obj.Label.Mentions.Mention:\n",
    "                entity = {}\n",
    "                entity['id'] = mention['id']\n",
    "                entity['section'] = mention['section']\n",
    "                entity['type'] = mention['type']\n",
    "                entity['start'] = mention['start']\n",
    "                entity['len'] = mention['len']\n",
    "                Y.append(entity)\n",
    "\n",
    "        return X, Y\n",
    "\n",
    "    def parse_test_xml(self, filename):\n",
    "        \"\"\"\n",
    "        @input a filename string\n",
    "        @return: directory X\n",
    "        \"\"\"\n",
    "        X = {}\n",
    "\n",
    "        obj = untangle.parse(filename)\n",
    "        for text in obj.Label.Text.Section:\n",
    "            X[text['id']] = text.cdata\n",
    "\n",
    "        return X\n",
    "\n",
    "    def fit(self, train_folder_path):\n",
    "        '''\n",
    "        # train ner model on training files\n",
    "\n",
    "        :param folder:  dictionary of training files\n",
    "        '''\n",
    "\n",
    "        url_base = os.getcwd() + '/' + train_folder_path + '/'\n",
    "        train_text_ls = glob.glob(url_base + '*.xml')\n",
    "        train_text_ls = train_text_ls[:10]  # for test, delete\n",
    "\n",
    "        for doc in train_text_ls:\n",
    "            train_x, train_y = self.parse_train_xml(doc)\n",
    "\n",
    "            # convert train_y into {s1: [(start,len, type),...], s2: [(),...],...}\n",
    "            train_y_dir = {}\n",
    "            for item in train_y:\n",
    "                key = item['section']\n",
    "                val_tuple = (item['start'], item['len'], item['type'])\n",
    "                if key not in train_y_dir:\n",
    "                    train_y_dir[key] = [val_tuple]\n",
    "                else:\n",
    "                    train_y_dir[key].append(val_tuple)\n",
    "\n",
    "            # add entities into trainer\n",
    "            for section, tuples in train_y_dir.iteritems():\n",
    "                tokens = tokenize(train_x[section])\n",
    "                trainer_instance = ner_training_instance(tokens)\n",
    "                for t in tuples:\n",
    "                    try:\n",
    "                        trainer_instance.add_entity(xrange(int(t[0]), int(t[0]) + int(t[1])), t[2])\n",
    "                    except:\n",
    "                        continue\n",
    "                self.trainer.add(trainer_instance)\n",
    "\n",
    "            self.ner = self.trainer.train()\n",
    "            self.ner.save_to_disk(\"custom_ner_model.dat\") # for test, delete\n",
    "\n",
    "    def predict(self, test_folder_path):\n",
    "        '''\n",
    "        # fit model on test dataset\n",
    "\n",
    "        :param model:  trained model\n",
    "        '''\n",
    "        print \"Model trained with tags:\", self.ner.get_possible_ner_tags()\n",
    "\n",
    "        url_base = os.getcwd() + '/' + test_folder_path + '/'\n",
    "        test_text_ls = glob.glob(url_base + '*.xml')\n",
    "        test_text_ls = test_text_ls[:2]  # for test, delete\n",
    "\n",
    "        for doc in test_text_ls:\n",
    "            test_x = self.parse_test_xml(doc)\n",
    "            for s in test_x:\n",
    "                # Let's get a test instance\n",
    "                tokens = tokenize(test_x[s])\n",
    "                entities = self.ner.extract_entities(tokens)\n",
    "\n",
    "                # Print the test instance and all entities found.\n",
    "                print 'Test instance:', ' '.join(tokens)\n",
    "                for e in entities:\n",
    "                    range = e[0]\n",
    "                    tag = e[1]\n",
    "                    entity_text = ' '.join(tokens[i] for i in range)\n",
    "                    print s + '  ' + tag + ': ' + entity_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model trained with tags:"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_possible_ner_tags'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-0a2f59f0fd00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNERModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/jzhu/git/nlp_adversedrug/data/train_xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/jzhu/git/nlp_adversedrug/data/unannotated_xml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-757f7c427bd6>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_folder_path)\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mtrained\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         '''\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Model trained with tags:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_possible_ner_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0murl_base\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_folder_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_possible_ner_tags'"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    ner = NERModel()\n",
    "    ner.fit(\"/Users/jzhu/git/nlp_adversedrug/data/train_xml\")\n",
    "    ner.predict(\"/Users/jzhu/git/nlp_adversedrug/data/unannotated_xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
