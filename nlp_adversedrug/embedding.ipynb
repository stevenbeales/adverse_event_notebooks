{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://gist.github.com/dirko/1d596ca757a541da96ac3caa6f291229\n",
    "\n",
    "http://dirko.github.io/Bidirectional-LSTMs-with-Keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# author: Keras==1.0.6\n",
    "# mine: Keras==1.2.1\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import TimeDistributedDense, Activation\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Merge\n",
    "from keras.backend import tf\n",
    "from keras.metrics import fmeasure # removed in Kereas 2.0 \n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from xml.dom import minidom\n",
    "\n",
    "from lambdawithmask import Lambda as MaskLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode(x, n):\n",
    "    result = np.zeros(n)\n",
    "    result[x] = 1\n",
    "    return result\n",
    "\n",
    "def chunks(l, n):\n",
    "    \"\"\"Yield successive n-sized chunks from l.\"\"\"\n",
    "    for i in range(0, len(l), n):\n",
    "        yield l[i:i + n]\n",
    "        \n",
    "def reverse_func(x, mask=None):\n",
    "    return tf.reverse(x, [False, True, False])\n",
    "\n",
    "def score1(yh, pr):\n",
    "    coords = [np.where(yhh > 0)[0][0] for yhh in yh]\n",
    "    yh = [yhh[co:] for yhh, co in zip(yh, coords)]\n",
    "    ypr = [prr[co:] for prr, co in zip(pr, coords)]\n",
    "    fyh = [c for row in yh for c in row]\n",
    "    fpr = [c for row in ypr for c in row]\n",
    "    return fyh, fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prettify(elem):\n",
    "    \"\"\"Return a pretty-printed XML string for the Element.\n",
    "    \"\"\"\n",
    "    rough_string = ElementTree.tostring(elem, 'utf-8')\n",
    "    reparsed = minidom.parseString(rough_string)\n",
    "    return reparsed.toprettyxml(indent=\"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw = open('train.csv', 'r').readlines()\n",
    "all_x = []\n",
    "point = []\n",
    "for line in raw:\n",
    "    stripped_line = line.strip().split(',')\n",
    "    point.append(stripped_line)\n",
    "    if line == '\"\"\\r\\n':\n",
    "#         print \"newline\"\n",
    "        all_x.append(point[:-1])\n",
    "        point = []\n",
    "all_x = all_x[:-1]\n",
    "lengths = [len(x) for x in all_x]\n",
    "# short_x = [x for x in all_x if len(x) < 64]\n",
    "\n",
    "# split long sections into chucks (a mimic of sentences)\n",
    "short_x = []\n",
    "for l in all_x:\n",
    "    short_x.extend(chunks(l, 64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3428"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(short_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = [[c[0] for c in x] for x in short_x]\n",
    "y = [[c[1] for c in y] for y in short_x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input sequence length range:  4741 58\n"
     ]
    }
   ],
   "source": [
    "all_text = [c for x in X for c in x]\n",
    "words = list(set(all_text))\n",
    "word2ind = {word: index for index, word in enumerate(words)}\n",
    "ind2word = {index: word for index, word in enumerate(words)}\n",
    "labels = list(set([c for x in y for c in x]))\n",
    "# label2ind = {label: (index + 1) for index, label in enumerate(labels)}\n",
    "# ind2label = {(index + 1): label for index, label in enumerate(labels)}\n",
    "label2ind = {label: (index) for index, label in enumerate(labels)}\n",
    "ind2label = {(index): label for index, label in enumerate(labels)}\n",
    "print 'Input sequence length range: ', max(lengths), min(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Severity',\n",
       " 1: 'Negation',\n",
       " 2: 'O',\n",
       " 3: 'DrugClass',\n",
       " 4: 'Animal',\n",
       " 5: 'Factor',\n",
       " 6: 'AdverseReaction'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum sequence length: 64\n"
     ]
    }
   ],
   "source": [
    "maxlen = max([len(x) for x in X])\n",
    "print 'Maximum sequence length:', maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_enc = [[word2ind[c] for c in x] for x in X]\n",
    "X_enc_reverse = [[c for c in reversed(x)] for x in X_enc]\n",
    "max_label = max(label2ind.values()) + 1\n",
    "# max_label = max(label2ind.values())\n",
    "y_enc = [[0] * (maxlen - len(ey)) + [label2ind[c] for c in ey] for ey in y]\n",
    "y_enc = [[encode(c, max_label) for c in ey] for ey in y_enc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  1.,  0.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_enc[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_enc_f = pad_sequences(X_enc, maxlen=maxlen)\n",
    "X_enc_b = pad_sequences(X_enc_reverse, maxlen=maxlen)\n",
    "y_enc = pad_sequences(y_enc, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and testing tensor shapes:\n",
      "(1440, 64) (352, 64) (1440, 64) (352, 64) (1440, 64, 7) (352, 64, 7)\n"
     ]
    }
   ],
   "source": [
    "(X_train_f, X_test_f, X_train_b,\n",
    " X_test_b, y_train, y_test) = train_test_split(X_enc_f, X_enc_b, y_enc,\n",
    "                                               test_size=11*32, train_size=45*32, random_state=42)\n",
    "print 'Training and testing tensor shapes:'\n",
    "print X_train_f.shape, X_test_f.shape, X_train_b.shape, X_test_b.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_features = len(word2ind)\n",
    "embedding_size = 128\n",
    "hidden_size = 32\n",
    "out_size = len(label2ind) #+ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_forward = Sequential()\n",
    "model_forward.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model_forward.add(LSTM(hidden_size, return_sequences=True))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_backward = Sequential()\n",
    "model_backward.add(Embedding(max_features, embedding_size, input_length=maxlen, mask_zero=True))\n",
    "model_backward.add(LSTM(hidden_size, return_sequences=True))\n",
    "model_backward.add(MaskLambda(function=reverse_func, mask_function=reverse_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Merge([model_forward, model_backward], mode='concat'))\n",
    "model.add(TimeDistributedDense(out_size))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[fmeasure])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1440 samples, validate on 352 samples\n",
      "Epoch 1/15\n",
      "1440/1440 [==============================] - 8s - loss: 0.3911 - fmeasure: 0.9048 - val_loss: 0.2994 - val_fmeasure: 0.9132\n",
      "Epoch 2/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.1868 - fmeasure: 0.9539 - val_loss: 0.2360 - val_fmeasure: 0.9358\n",
      "Epoch 3/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.1417 - fmeasure: 0.9655 - val_loss: 0.2132 - val_fmeasure: 0.9392\n",
      "Epoch 4/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.1174 - fmeasure: 0.9703 - val_loss: 0.2018 - val_fmeasure: 0.9406\n",
      "Epoch 5/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0999 - fmeasure: 0.9764 - val_loss: 0.1930 - val_fmeasure: 0.9436\n",
      "Epoch 6/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0878 - fmeasure: 0.9810 - val_loss: 0.1835 - val_fmeasure: 0.9461\n",
      "Epoch 7/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0794 - fmeasure: 0.9818 - val_loss: 0.1799 - val_fmeasure: 0.9470\n",
      "Epoch 8/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0728 - fmeasure: 0.9830 - val_loss: 0.1784 - val_fmeasure: 0.9465\n",
      "Epoch 9/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0674 - fmeasure: 0.9841 - val_loss: 0.1767 - val_fmeasure: 0.9479\n",
      "Epoch 10/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0632 - fmeasure: 0.9850 - val_loss: 0.1768 - val_fmeasure: 0.9477\n",
      "Epoch 11/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0597 - fmeasure: 0.9860 - val_loss: 0.1744 - val_fmeasure: 0.9484\n",
      "Epoch 12/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0568 - fmeasure: 0.9866 - val_loss: 0.1744 - val_fmeasure: 0.9490\n",
      "Epoch 13/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0542 - fmeasure: 0.9871 - val_loss: 0.1721 - val_fmeasure: 0.9491\n",
      "Epoch 14/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0522 - fmeasure: 0.9873 - val_loss: 0.1705 - val_fmeasure: 0.9489\n",
      "Epoch 15/15\n",
      "1440/1440 [==============================] - 6s - loss: 0.0504 - fmeasure: 0.9877 - val_loss: 0.1706 - val_fmeasure: 0.9491\n",
      "352/352 [==============================] - 0s     \n",
      "('Raw test score:', [0.17060929672284561, 0.94905072992498229])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 #32\n",
    "model.fit([X_train_f, X_train_b], y_train, batch_size=batch_size, nb_epoch=15, # started from 40\n",
    "          validation_data=([X_test_f, X_test_b], y_test))\n",
    "score = model.evaluate([X_test_f, X_test_b], y_test, batch_size=batch_size)\n",
    "print('Raw test score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1440/1440 [==============================] - 1s     \n",
      "Training Micro F1: 0.997880615523\n",
      "Training confusion matrix:\n",
      "[[  339     0    26     0     0     0     2]\n",
      " [    0     0    33     0     0     7     2]\n",
      " [    7     0 82132     0     0     3     9]\n",
      " [    6     0    39    45     0     3     6]\n",
      " [    0     0     7     0     4     2     1]\n",
      " [    1     0    24     0     0   239     2]\n",
      " [    1     0     7     0     0     0  5758]]\n",
      "\n",
      "Training Micro F1 (without Class O): 0.991921702657\n",
      "Training confusion matrix:\n",
      "[[ 339    0    0    0    0    0    2]\n",
      " [   0    0    0    0    0    7    2]\n",
      " [   7    0    0    0    0    3    9]\n",
      " [   6    0    0   45    0    3    6]\n",
      " [   0    0    0    0    4    2    1]\n",
      " [   1    0    0    0    0  239    2]\n",
      " [   1    0    0    0    0    0 5758]]\n"
     ]
    }
   ],
   "source": [
    "pr = model.predict_classes([X_train_f, X_train_b])\n",
    "yh = y_train.argmax(2)\n",
    "fyh, fpr = score1(yh, pr)\n",
    "print 'Training Micro F1:', f1_score(fyh, fpr, average='micro')\n",
    "print 'Training confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)\n",
    "print\n",
    "\n",
    "# calculate F1 without class 'O'\n",
    "NO_inds = [i for i,v in enumerate(fpr) if v != 2]\n",
    "fyh = [fyh[i] for i in NO_inds]\n",
    "fpr = [fpr[i] for i in NO_inds]\n",
    "print 'Training Micro F1 (without Class O):', f1_score(fyh, fpr, average='micro')\n",
    "print 'Training confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "352/352 [==============================] - 0s     \n",
      "Training Micro F1: 0.972244140172\n",
      "Training confusion matrix:\n",
      "[[   40     0    37     0     0     0     5]\n",
      " [    0     0    12     0     0     1     0]\n",
      " [   34     0 19763     0     0    12   131]\n",
      " [    2     0    21     1     0     1    10]\n",
      " [    0     0     1     0     0     1     1]\n",
      " [    0     0    27     0     0    11     0]\n",
      " [    2     0   300     0     0     0  1132]]\n",
      "\n",
      "Training Micro F1 (without Class O): 0.85549132948\n",
      "Training confusion matrix:\n",
      "[[  40    0    0    0    0    0    5]\n",
      " [   0    0    0    0    0    1    0]\n",
      " [  34    0    0    0    0   12  131]\n",
      " [   2    0    0    1    0    1   10]\n",
      " [   0    0    0    0    0    1    1]\n",
      " [   0    0    0    0    0   11    0]\n",
      " [   2    0    0    0    0    0 1132]]\n"
     ]
    }
   ],
   "source": [
    "pr = model.predict_classes([X_test_f, X_test_b])\n",
    "yh = y_test.argmax(2)\n",
    "fyh, fpr = score1(yh, pr)\n",
    "print 'Training Micro F1:', f1_score(fyh, fpr, average='micro')\n",
    "print 'Training confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)\n",
    "print\n",
    "\n",
    "# calculate F1 without class 'O'\n",
    "NO_inds = [i for i,v in enumerate(fpr) if v != 2]\n",
    "fyh = [fyh[i] for i in NO_inds]\n",
    "fpr = [fpr[i] for i in NO_inds]\n",
    "print 'Training Micro F1 (without Class O):', f1_score(fyh, fpr, average='micro')\n",
    "print 'Training confusion matrix:'\n",
    "print confusion_matrix(fyh, fpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Severity',\n",
       " 1: 'Negation',\n",
       " 2: 'O',\n",
       " 3: 'DrugClass',\n",
       " 4: 'Animal',\n",
       " 5: 'Factor',\n",
       " 6: 'AdverseReaction'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind2label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: \n",
    "nb_epoch=15 is the best so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 64) (1, 64)\n"
     ]
    }
   ],
   "source": [
    "doc = \"Classical HL post-auto-HSCT consolidation: neutropenia, peripheral sensory neuropathy, thrombocytopenia, anemia, upper respiratory tract infection, fatigue, peripheral motor neuropathy, nausea, cough, and diarrhea.\"\n",
    "x_new = [[m.group(0) for m in re.finditer(r'\\w+', doc)]] # tokenize words only\n",
    "\n",
    "X_new = [[word2ind[c] for c in x] for x in x_new]\n",
    "X_new_reverse = [[c for c in reversed(x)] for x in X_new]\n",
    "X_new_f = pad_sequences(X_new, maxlen=maxlen)\n",
    "X_new_b = pad_sequences(X_new_reverse, maxlen=maxlen)\n",
    "print X_new_f.shape, X_new_b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2, 2, 0, 6, 6, 6, 6, 6, 6, 2, 2, 2, 2, 6, 6, 6, 0, 6, 6, 0,\n",
       "        2, 6, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2,\n",
       "        2, 2, 6, 6, 6, 6, 6, 6, 2, 6, 2, 6, 6, 6, 2, 6, 6, 6, 2, 6]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = model.predict_classes([X_new_f, X_new_b])\n",
    "pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical O\n",
      "HL O\n",
      "post O\n",
      "auto O\n",
      "HSCT O\n",
      "consolidation O\n",
      "neutropenia AdverseReaction\n",
      "peripheral AdverseReaction\n",
      "sensory AdverseReaction\n",
      "neuropathy AdverseReaction\n",
      "thrombocytopenia AdverseReaction\n",
      "anemia AdverseReaction\n",
      "upper O\n",
      "respiratory AdverseReaction\n",
      "tract O\n",
      "infection AdverseReaction\n",
      "fatigue AdverseReaction\n",
      "peripheral AdverseReaction\n",
      "motor O\n",
      "neuropathy AdverseReaction\n",
      "nausea AdverseReaction\n",
      "cough AdverseReaction\n",
      "and O\n",
      "diarrhea AdverseReaction\n"
     ]
    }
   ],
   "source": [
    "for w, p in zip(x_new[0], pr.tolist()[0][-len(X_new[0]):]):\n",
    "    print w, ind2label[p]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues:\n",
    "* Cannot identify names with more than one word (how?)\n",
    "* Two classes are missing in training data (why?)\n",
    "* How to calculate and improve F1 score? Overfitting? How to tune parameters?\n",
    "* Imbalanced dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write submission file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://bionlp.nlm.nih.gov/tac2017adversereactions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testpath = '/Users/jzhu/git/nlp_adversedrug/data/unannotated_xml'\n",
    "outpath = '/Users/jzhu/git/nlp_adversedrug/data/labeled_unannotated_xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3594380, 5)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('test.csv', header=None)\n",
    "test.columns = ['file', 'section', 'word', 'start', 'end']\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>section</th>\n",
       "      <th>word</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8MOP</td>\n",
       "      <td>S2</td>\n",
       "      <td>BOXED</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8MOP</td>\n",
       "      <td>S2</td>\n",
       "      <td>WARNING</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8MOP</td>\n",
       "      <td>S2</td>\n",
       "      <td>Methoxsalen</td>\n",
       "      <td>25</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8MOP</td>\n",
       "      <td>S2</td>\n",
       "      <td>with</td>\n",
       "      <td>37</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8MOP</td>\n",
       "      <td>S2</td>\n",
       "      <td>UV</td>\n",
       "      <td>42</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   file section         word  start  end\n",
       "0  8MOP      S2        BOXED      6   11\n",
       "1  8MOP      S2      WARNING     12   19\n",
       "2  8MOP      S2  Methoxsalen     25   36\n",
       "3  8MOP      S2         with     37   41\n",
       "4  8MOP      S2           UV     42   44"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4311, 2)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sec = test[['file', 'section']].drop_duplicates().reset_index(drop=True)\n",
    "all_sec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument to reversed() must be a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-9e8d70d05e14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword2ind\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2ind\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mX_new_reverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX_new\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mX_new_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mX_new_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_new_reverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: argument to reversed() must be a sequence"
     ]
    }
   ],
   "source": [
    "for index, row in all_sec.iterrows():\n",
    "    temp = test[(test['file'] == row['file']) & (test['section'] == row['section'])]\n",
    "    x_new = temp['word']\n",
    "    \n",
    "    X_new = [[word2ind[c] if c in word2ind else 0 for c in x] for x in x_new]\n",
    "    X_new_reverse = [[c for c in reversed(x)] for x in X_new]\n",
    "    X_new_f = pad_sequences(X_new, maxlen=maxlen)\n",
    "    X_new_b = pad_sequences(X_new_reverse, maxlen=maxlen)\n",
    "    \n",
    "    pr = model.predict_classes([X_new_f, X_new_azb]).tolist()\n",
    "#     print temp['word']\n",
    "    for w, p in zip(x_new, pr[-len(X_new):]):\n",
    "        print w, ind2label[p]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_new_f[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
